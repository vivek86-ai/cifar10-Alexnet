{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (0.16.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from scikit-image) (7.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from scikit-image) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from scipy>=0.19.0->scikit-image) (1.18.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\vivek\\anaconda3\\envs\\tfod\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing cifar10 datasets\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train),(x_test, y_test) =  cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching only 1000 rows for each i.e. x_train, y_train, x_test, y_test\n",
    "x_train = x_train[:1000]\n",
    "x_test = x_test[:1000]\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below function transform image size to Imagenet size i.e. 224x224x3\n",
    "from skimage.util import img_as_ubyte\n",
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_imagenet_size(images):\n",
    "  tmp_images = []\n",
    "  \n",
    "  for image in images:\n",
    "    image = skimage.transform.resize(image,(224,224),mode='constant')\n",
    "    image = img_as_ubyte(image)\n",
    "    tmp_images.append(image)\n",
    "   \n",
    "  return np.array(tmp_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#checking image shape before transforming \n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = convert_to_imagenet_size(x_train)\n",
    "x_test = convert_to_imagenet_size(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3)\n",
      "(1000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#checking image shape after passing thru \"convert_to_imagenet_size\" function\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying one hot encoding on _train, y_test\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "#Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'))\n",
    "# Pooling \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid', activation='relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 28,089,762\n",
      "Trainable params: 28,068,626\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "800/800 [==============================] - 76s 95ms/step - loss: 3.0564 - accuracy: 0.1775 - val_loss: 11.8141 - val_accuracy: 0.1150\n",
      "Epoch 2/5\n",
      "800/800 [==============================] - 76s 95ms/step - loss: 2.7873 - accuracy: 0.2587 - val_loss: 51.5046 - val_accuracy: 0.0850\n",
      "Epoch 3/5\n",
      "800/800 [==============================] - 76s 95ms/step - loss: 2.3602 - accuracy: 0.2725 - val_loss: 69.9181 - val_accuracy: 0.0850\n",
      "Epoch 4/5\n",
      "800/800 [==============================] - 76s 95ms/step - loss: 2.1224 - accuracy: 0.3350 - val_loss: 64.8057 - val_accuracy: 0.0850\n",
      "Epoch 5/5\n",
      "800/800 [==============================] - 76s 96ms/step - loss: 1.9193 - accuracy: 0.3500 - val_loss: 48.0894 - val_accuracy: 0.0850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26094b70>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting Model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=5,verbose=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 22s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss =  49.48676263427734\n",
      "Test Accuracy =  0.10599999874830246\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss = \", scores[0])\n",
    "print(\"Test Accuracy = \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
